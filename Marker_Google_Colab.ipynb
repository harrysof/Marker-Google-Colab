{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Marker PDF Converter - Google Colab Setup\n",
        "\n",
        "This notebook sets up [Marker](https://github.com/VikParuchuri/marker) - a tool that converts PDFs, images, PPTX, DOCX, XLSX, HTML, and EPUB files to markdown, JSON, chunks, and HTML.\n",
        "\n",
        "**Features:**\n",
        "- Converts documents in all languages\n",
        "- Formats tables, forms, equations, inline math, links, and code blocks\n",
        "- Extracts and saves images\n",
        "- Works on GPU, CPU, or MPS\n",
        "- Optional LLM mode for highest accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "check-gpu"
      },
      "source": [
        "## 1. Check GPU Availability\n",
        "\n",
        "First, let's verify that GPU is enabled in Colab. Go to **Runtime → Change runtime type** and select **T4 GPU** or higher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check-gpu-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "949a85bc-e710-4e39-9398-1cba748b02b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Feb  9 00:23:57 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "installation"
      },
      "source": [
        "## 2. Install Marker\n",
        "\n",
        "Installing marker-pdf with full support for all document types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-marker",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2585157b-3148-4583-b249-90fffd336ed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/115.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.2/223.2 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m127.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.9/189.9 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.7/195.7 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.4/566.4 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m132.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.1/847.1 kB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ebooklib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "✓ Marker installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install marker with full document support\n",
        "!pip install -q marker-pdf[full]\n",
        "\n",
        "print(\"✓ Marker installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload-section"
      },
      "source": [
        "## 3. Upload Your Document\n",
        "\n",
        "Upload a PDF, image, PPTX, DOCX, XLSX, HTML, or EPUB file to convert."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload-file",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "fd8d8c7e-ad38-452b-dd25-40bd05a9cdf3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4554051e-2678-40b9-ab4d-bb45f2196803\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4554051e-2678-40b9-ab4d-bb45f2196803\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1-G50 CONSOLIDER MOIS DE JANVIER 2025.pdf to 1-G50 CONSOLIDER MOIS DE JANVIER 2025.pdf\n",
            "\n",
            "✓ Uploaded: 1-G50 CONSOLIDER MOIS DE JANVIER 2025.pdf\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Upload file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded filename\n",
        "input_file = list(uploaded.keys())[0]\n",
        "print(f\"\\n✓ Uploaded: {input_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "optional-llm"
      },
      "source": [
        "## 4. (Optional) Configure LLM Mode\n",
        "\n",
        "For highest accuracy, you can enable LLM mode with Gemini. This improves table formatting, inline math, and form extraction.\n",
        "\n",
        "**To use LLM mode:**\n",
        "1. Get a free Gemini API key from [Google AI Studio](https://makersuite.google.com/app/apikey)\n",
        "2. Uncomment and run the cell below\n",
        "3. Enter your API key when prompted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup-llm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9ee14fe-b14d-452e-9d06-0ff352aec03e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Gemini API key: ··········\n",
            "✓ Gemini API key configured!\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to enable LLM mode\n",
        "from getpass import getpass\n",
        "import os\n",
        "api_key = getpass(\"Enter your Gemini API key: \")\n",
        "os.environ['GOOGLE_API_KEY'] = api_key\n",
        "print(\"✓ Gemini API key configured!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "convert-section"
      },
      "source": [
        "## 5. Convert Document to Markdown/Html:\n",
        "\n",
        "\n",
        "\n",
        "Convert your document to markdown/html format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "convert-basic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5229e9d9-5678-4ae7-ed4a-5fdc459844d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-09 00:31:06.602622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770597066.622302    2281 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770597066.628350    2281 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770597066.643280    2281 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770597066.643309    2281 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770597066.643313    2281 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770597066.643316    2281 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-09 00:31:06.647902: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Downloading manifest.json: 100% 262/262 [00:00<00:00, 858kB/s]\n",
            "Downloading layout model to /root/.cache/datalab/models/layout/2025_09_23:   0% 0/12 [00:00<?, ?it/s]\n",
            "Downloading vocab_math.json: 100% 20.1k/20.1k [00:00<00:00, 50.8MB/s]\n",
            "\n",
            "Downloading README.md: 100% 5.05k/5.05k [00:00<00:00, 21.2MB/s]\n",
            "\n",
            "Downloading specials_dict.json: 100% 43.5k/43.5k [00:00<00:00, 71.4MB/s]\n",
            "\n",
            "Downloading .gitattributes:   0% 0.00/1.48k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading .gitattributes: 100% 1.48k/1.48k [00:00<00:00, 951kB/s]\n",
            "Downloading tokenizer_config.json: 100% 694/694 [00:00<00:00, 866kB/s]\n",
            "Downloading layout model to /root/.cache/datalab/models/layout/2025_09_23:   8% 1/12 [00:00<00:03,  3.33it/s]\n",
            "Downloading preprocessor_config.json: 100% 419/419 [00:00<00:00, 2.10MB/s]\n",
            "\n",
            "Downloading special_tokens_map.json: 100% 278/278 [00:00<00:00, 1.87MB/s]\n",
            "\n",
            "Downloading config.json: 100% 50.4k/50.4k [00:00<00:00, 106MB/s]\n",
            "\n",
            "Downloading processor_config.json: 100% 411/411 [00:00<00:00, 1.60MB/s]\n",
            "\n",
            "Downloading model.safetensors:   0% 0.00/1.35G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading specials.json:   0% 0.00/19.6k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading training_args.bin: 100% 7.45k/7.45k [00:00<00:00, 20.7MB/s]\n",
            "Downloading specials.json: 100% 19.6k/19.6k [00:00<00:00, 15.8MB/s]\n",
            "\n",
            "Downloading model.safetensors:   0% 1.00M/1.35G [00:01<23:47, 1.01MB/s]\u001b[A\n",
            "Downloading model.safetensors:   0% 2.00M/1.35G [00:01<13:01, 1.85MB/s]\u001b[A\n",
            "Downloading model.safetensors:   0% 3.00M/1.35G [00:01<08:34, 2.80MB/s]\u001b[A\n",
            "Downloading model.safetensors:   0% 4.00M/1.35G [00:01<06:05, 3.94MB/s]\u001b[A\n",
            "Downloading model.safetensors:   0% 6.00M/1.35G [00:01<03:43, 6.43MB/s]\u001b[A\n",
            "Downloading model.safetensors:   1% 8.00M/1.35G [00:01<02:36, 9.16MB/s]\u001b[A\n",
            "Downloading model.safetensors:   1% 11.0M/1.35G [00:01<01:46, 13.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:   1% 15.0M/1.35G [00:01<01:13, 19.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:   1% 20.0M/1.35G [00:02<00:52, 27.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:   2% 27.0M/1.35G [00:02<00:36, 38.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:   3% 36.0M/1.35G [00:02<00:26, 52.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:   3% 48.0M/1.35G [00:02<00:19, 72.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:   4% 62.0M/1.35G [00:02<00:15, 91.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:   5% 72.0M/1.35G [00:02<00:14, 94.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:   6% 84.0M/1.35G [00:02<00:13, 102MB/s] \u001b[A\n",
            "Downloading model.safetensors:   7% 95.0M/1.35G [00:02<00:12, 104MB/s]\u001b[A\n",
            "Downloading model.safetensors:   8% 105M/1.35G [00:02<00:12, 104MB/s] \u001b[A\n",
            "Downloading model.safetensors:   8% 114M/1.35G [00:03<00:13, 100MB/s]\u001b[A\n",
            "Downloading model.safetensors:   9% 125M/1.35G [00:03<00:12, 103MB/s]\u001b[A\n",
            "Downloading model.safetensors:  10% 138M/1.35G [00:03<00:11, 111MB/s]\u001b[A\n",
            "Downloading model.safetensors:  11% 148M/1.35G [00:03<00:11, 109MB/s]\u001b[A\n",
            "Downloading model.safetensors:  11% 158M/1.35G [00:03<00:11, 107MB/s]\u001b[A\n",
            "Downloading model.safetensors:  12% 171M/1.35G [00:03<00:11, 115MB/s]\u001b[A\n",
            "Downloading model.safetensors:  13% 182M/1.35G [00:03<00:11, 107MB/s]\u001b[A\n",
            "Downloading model.safetensors:  14% 194M/1.35G [00:03<00:11, 110MB/s]\u001b[A\n",
            "Downloading model.safetensors:  15% 205M/1.35G [00:03<00:11, 110MB/s]\u001b[A\n",
            "Downloading model.safetensors:  16% 218M/1.35G [00:03<00:10, 116MB/s]\u001b[A\n",
            "Downloading model.safetensors:  17% 228M/1.35G [00:04<00:10, 112MB/s]\u001b[A\n",
            "Downloading model.safetensors:  17% 238M/1.35G [00:04<00:10, 110MB/s]\u001b[A\n",
            "Downloading model.safetensors:  18% 247M/1.35G [00:04<00:11, 105MB/s]\u001b[A\n",
            "Downloading model.safetensors:  19% 259M/1.35G [00:04<00:10, 110MB/s]\u001b[A\n",
            "Downloading model.safetensors:  20% 272M/1.35G [00:04<00:09, 118MB/s]\u001b[A\n",
            "Downloading model.safetensors:  21% 284M/1.35G [00:04<00:09, 119MB/s]\u001b[A\n",
            "Downloading model.safetensors:  21% 294M/1.35G [00:04<00:09, 115MB/s]\u001b[A\n",
            "Downloading model.safetensors:  22% 303M/1.35G [00:04<00:10, 107MB/s]\u001b[A\n",
            "Downloading model.safetensors:  22% 310M/1.35G [00:04<00:12, 92.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  23% 320M/1.35G [00:05<00:12, 90.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  24% 331M/1.35G [00:05<00:11, 95.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  25% 342M/1.35G [00:05<00:11, 97.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  26% 352M/1.35G [00:05<00:10, 99.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  26% 363M/1.35G [00:05<00:10, 101MB/s] \u001b[A\n",
            "Downloading model.safetensors:  27% 375M/1.35G [00:05<00:09, 106MB/s]\u001b[A\n",
            "Downloading model.safetensors:  28% 386M/1.35G [00:05<00:09, 108MB/s]\u001b[A\n",
            "Downloading model.safetensors:  29% 397M/1.35G [00:05<00:09, 108MB/s]\u001b[A\n",
            "Downloading model.safetensors:  30% 409M/1.35G [00:05<00:09, 112MB/s]\u001b[A\n",
            "Downloading model.safetensors:  30% 420M/1.35G [00:05<00:09, 111MB/s]\u001b[A\n",
            "Downloading model.safetensors:  31% 430M/1.35G [00:06<00:09, 108MB/s]\u001b[A\n",
            "Downloading model.safetensors:  32% 439M/1.35G [00:06<00:09, 102MB/s]\u001b[A\n",
            "Downloading model.safetensors:  32% 448M/1.35G [00:06<00:09, 99.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  33% 458M/1.35G [00:06<00:09, 98.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  34% 469M/1.35G [00:06<00:09, 100MB/s] \u001b[A\n",
            "Downloading model.safetensors:  35% 481M/1.35G [00:06<00:08, 106MB/s]\u001b[A\n",
            "Downloading model.safetensors:  36% 493M/1.35G [00:06<00:08, 110MB/s]\u001b[A\n",
            "Downloading model.safetensors:  37% 504M/1.35G [00:06<00:08, 111MB/s]\u001b[A\n",
            "Downloading model.safetensors:  37% 516M/1.35G [00:06<00:07, 115MB/s]\u001b[A\n",
            "Downloading model.safetensors:  38% 528M/1.35G [00:07<00:07, 117MB/s]\u001b[A\n",
            "Downloading model.safetensors:  39% 541M/1.35G [00:07<00:07, 122MB/s]\u001b[A\n",
            "Downloading model.safetensors:  40% 553M/1.35G [00:07<00:07, 122MB/s]\u001b[A\n",
            "Downloading model.safetensors:  41% 562M/1.35G [00:07<00:07, 113MB/s]\u001b[A\n",
            "Downloading model.safetensors:  42% 574M/1.35G [00:07<00:07, 116MB/s]\u001b[A\n",
            "Downloading model.safetensors:  43% 586M/1.35G [00:07<00:07, 110MB/s]\u001b[A\n",
            "Downloading model.safetensors:  43% 597M/1.35G [00:07<00:07, 110MB/s]\u001b[A\n",
            "Downloading model.safetensors:  44% 610M/1.35G [00:07<00:06, 116MB/s]\u001b[A\n",
            "Downloading model.safetensors:  45% 622M/1.35G [00:07<00:06, 118MB/s]\u001b[A\n",
            "Downloading model.safetensors:  46% 633M/1.35G [00:07<00:06, 117MB/s]\u001b[A\n",
            "Downloading model.safetensors:  47% 645M/1.35G [00:08<00:06, 117MB/s]\u001b[A\n",
            "Downloading model.safetensors:  47% 654M/1.35G [00:08<00:06, 109MB/s]\u001b[A\n",
            "Downloading model.safetensors:  48% 665M/1.35G [00:08<00:06, 110MB/s]\u001b[A\n",
            "Downloading model.safetensors:  49% 680M/1.35G [00:08<00:05, 123MB/s]\u001b[A\n",
            "Downloading model.safetensors:  50% 692M/1.35G [00:08<00:06, 116MB/s]\u001b[A\n",
            "Downloading model.safetensors:  51% 703M/1.35G [00:08<00:06, 116MB/s]\u001b[A\n",
            "Downloading model.safetensors:  52% 711M/1.35G [00:08<00:11, 62.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  52% 712M/1.35G [00:09<00:24, 28.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  52% 713M/1.35G [00:10<00:41, 17.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  52% 714M/1.35G [00:10<01:05, 10.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  52% 715M/1.35G [00:10<01:06, 10.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  53% 736M/1.35G [00:10<00:19, 34.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  56% 771M/1.35G [00:10<00:07, 80.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  59% 807M/1.35G [00:11<00:04, 130MB/s] \u001b[A\n",
            "Downloading model.safetensors:  61% 840M/1.35G [00:11<00:03, 171MB/s]\u001b[A\n",
            "Downloading model.safetensors:  63% 873M/1.35G [00:11<00:02, 208MB/s]\u001b[A\n",
            "Downloading model.safetensors:  66% 910M/1.35G [00:11<00:01, 248MB/s]\u001b[A\n",
            "Downloading model.safetensors:  67% 919M/1.35G [00:11<00:02, 208MB/s]\u001b[A\n",
            "Downloading model.safetensors:  67% 930M/1.35G [00:11<00:02, 181MB/s]\u001b[A\n",
            "Downloading model.safetensors:  68% 940M/1.35G [00:11<00:02, 160MB/s]\u001b[A\n",
            "Downloading model.safetensors:  69% 948M/1.35G [00:11<00:03, 138MB/s]\u001b[A\n",
            "Downloading model.safetensors:  70% 959M/1.35G [00:11<00:03, 129MB/s]\u001b[A\n",
            "Downloading model.safetensors:  70% 969M/1.35G [00:11<00:03, 121MB/s]\u001b[A\n",
            "Downloading model.safetensors:  71% 979M/1.35G [00:12<00:03, 115MB/s]\u001b[A\n",
            "Downloading model.safetensors:  72% 992M/1.35G [00:12<00:03, 120MB/s]\u001b[A\n",
            "Downloading model.safetensors:  73% 0.98G/1.35G [00:12<00:03, 123MB/s]\u001b[A\n",
            "Downloading model.safetensors:  74% 0.99G/1.35G [00:12<00:03, 125MB/s]\u001b[A\n",
            "Downloading model.safetensors:  75% 1.00G/1.35G [00:12<00:03, 113MB/s]\u001b[A\n",
            "Downloading model.safetensors:  75% 1.01G/1.35G [00:12<00:05, 71.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  76% 1.02G/1.35G [00:12<00:04, 83.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  77% 1.03G/1.35G [00:12<00:03, 87.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  77% 1.04G/1.35G [00:13<00:04, 67.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  78% 1.05G/1.35G [00:13<00:04, 75.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  79% 1.07G/1.35G [00:13<00:02, 101MB/s] \u001b[A\n",
            "Downloading model.safetensors:  79% 1.07G/1.35G [00:13<00:04, 69.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  81% 1.10G/1.35G [00:13<00:02, 126MB/s] \u001b[A\n",
            "Downloading model.safetensors:  83% 1.11G/1.35G [00:13<00:01, 138MB/s]\u001b[A\n",
            "Downloading model.safetensors:  83% 1.12G/1.35G [00:13<00:01, 127MB/s]\u001b[A\n",
            "Downloading model.safetensors:  84% 1.13G/1.35G [00:13<00:01, 123MB/s]\u001b[A\n",
            "Downloading model.safetensors:  85% 1.14G/1.35G [00:14<00:01, 119MB/s]\u001b[A\n",
            "Downloading model.safetensors:  86% 1.15G/1.35G [00:14<00:01, 116MB/s]\u001b[A\n",
            "Downloading model.safetensors:  87% 1.17G/1.35G [00:14<00:01, 114MB/s]\u001b[A\n",
            "Downloading model.safetensors:  87% 1.18G/1.35G [00:14<00:01, 119MB/s]\u001b[A\n",
            "Downloading model.safetensors:  88% 1.18G/1.35G [00:14<00:04, 43.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  88% 1.18G/1.35G [00:15<00:04, 37.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  88% 1.19G/1.35G [00:15<00:05, 34.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  89% 1.20G/1.35G [00:15<00:03, 51.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  90% 1.21G/1.35G [00:15<00:02, 53.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  90% 1.22G/1.35G [00:15<00:01, 70.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  91% 1.23G/1.35G [00:15<00:01, 75.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  92% 1.24G/1.35G [00:15<00:01, 90.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  93% 1.25G/1.35G [00:15<00:01, 96.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  93% 1.25G/1.35G [00:15<00:01, 68.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  94% 1.26G/1.35G [00:16<00:01, 77.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  95% 1.28G/1.35G [00:16<00:00, 109MB/s] \u001b[A\n",
            "Downloading model.safetensors:  97% 1.30G/1.35G [00:16<00:00, 139MB/s]\u001b[A\n",
            "Downloading model.safetensors:  97% 1.31G/1.35G [00:16<00:00, 128MB/s]\u001b[A\n",
            "Downloading model.safetensors:  98% 1.32G/1.35G [00:16<00:00, 120MB/s]\u001b[A\n",
            "Downloading model.safetensors:  99% 1.33G/1.35G [00:16<00:00, 114MB/s]\u001b[A\n",
            "Downloading model.safetensors: 100% 1.35G/1.35G [00:16<00:00, 86.4MB/s]\n",
            "Downloading layout model to /root/.cache/datalab/models/layout/2025_09_23: 100% 12/12 [00:17<00:00,  1.45s/it]\n",
            "Downloading manifest.json: 100% 262/262 [00:00<00:00, 916kB/s]\n",
            "Downloading text_recognition model to /root/.cache/datalab/models/text_recognition/2025_09_23:   0% 0/12 [00:00<?, ?it/s]\n",
            "Downloading training_args.bin: 100% 7.45k/7.45k [00:00<00:00, 23.8MB/s]\n",
            "\n",
            "Downloading specials_dict.json:   0% 0.00/43.5k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading vocab_math.json: 100% 20.1k/20.1k [00:00<00:00, 41.4MB/s]\n",
            "Downloading specials_dict.json: 100% 43.5k/43.5k [00:00<00:00, 15.5MB/s]\n",
            "\n",
            "Downloading .gitattributes: 100% 1.48k/1.48k [00:00<00:00, 7.96MB/s]\n",
            "Downloading text_recognition model to /root/.cache/datalab/models/text_recognition/2025_09_23:   8% 1/12 [00:00<00:03,  3.36it/s]\n",
            "Downloading specials.json:   0% 0.00/19.6k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading README.md:   0% 0.00/5.05k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading preprocessor_config.json:   0% 0.00/419 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading README.md: 100% 5.05k/5.05k [00:00<00:00, 3.30MB/s]\n",
            "Downloading preprocessor_config.json: 100% 419/419 [00:00<00:00, 278kB/s]\n",
            "Downloading special_tokens_map.json: 100% 278/278 [00:00<00:00, 237kB/s]\n",
            "Downloading specials.json: 100% 19.6k/19.6k [00:00<00:00, 3.71MB/s]\n",
            "\n",
            "Downloading config.json: 100% 50.2k/50.2k [00:00<00:00, 100MB/s]\n",
            "\n",
            "Downloading tokenizer_config.json: 100% 694/694 [00:00<00:00, 4.46MB/s]\n",
            "\n",
            "Downloading processor_config.json: 100% 411/411 [00:00<00:00, 1.55MB/s]\n",
            "Downloading text_recognition model to /root/.cache/datalab/models/text_recognition/2025_09_23:  92% 11/12 [00:00<00:00, 22.39it/s]\n",
            "Downloading model.safetensors:   0% 0.00/1.34G [00:00<?, ?B/s]\u001b[A\n",
            "Downloading model.safetensors:   0% 3.00M/1.34G [00:00<00:46, 30.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:   0% 6.00M/1.34G [00:00<00:46, 30.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:   1% 8.00M/1.34G [00:00<00:55, 25.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:   1% 11.0M/1.34G [00:00<00:51, 27.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:   1% 15.0M/1.34G [00:00<00:44, 32.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:   1% 19.0M/1.34G [00:00<00:40, 35.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:   2% 26.0M/1.34G [00:00<00:30, 46.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:   2% 33.0M/1.34G [00:00<00:26, 52.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:   3% 39.0M/1.34G [00:00<00:25, 54.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:   3% 41.0M/1.34G [00:01<00:31, 44.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:   3% 43.0M/1.34G [00:01<00:38, 35.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:   3% 46.0M/1.34G [00:01<00:40, 34.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:   4% 52.0M/1.34G [00:01<00:32, 42.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:   4% 59.0M/1.34G [00:01<00:27, 50.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:   5% 68.0M/1.34G [00:01<00:21, 62.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:   5% 73.0M/1.34G [00:01<00:24, 55.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:   6% 78.0M/1.34G [00:01<00:24, 54.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:   6% 86.0M/1.34G [00:01<00:23, 57.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:   7% 93.0M/1.34G [00:02<00:21, 61.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:   7% 100M/1.34G [00:02<00:20, 63.7MB/s] \u001b[A\n",
            "Downloading model.safetensors:   8% 104M/1.34G [00:02<00:24, 54.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:   8% 113M/1.34G [00:02<00:20, 64.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:   9% 121M/1.34G [00:02<00:18, 69.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:   9% 130M/1.34G [00:02<00:17, 74.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  10% 138M/1.34G [00:02<00:17, 74.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  11% 146M/1.34G [00:02<00:16, 77.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  11% 153M/1.34G [00:02<00:17, 74.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  12% 161M/1.34G [00:03<00:16, 77.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  12% 167M/1.34G [00:03<00:17, 72.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  13% 173M/1.34G [00:03<00:18, 68.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  13% 181M/1.34G [00:03<00:17, 72.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  14% 187M/1.34G [00:03<00:18, 68.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  14% 194M/1.34G [00:03<00:17, 69.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  15% 202M/1.34G [00:03<00:16, 72.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  15% 206M/1.34G [00:03<00:21, 56.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  16% 215M/1.34G [00:03<00:18, 64.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  16% 226M/1.34G [00:03<00:15, 77.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  17% 232M/1.34G [00:04<00:16, 72.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  17% 239M/1.34G [00:04<00:17, 69.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  18% 245M/1.34G [00:04<00:17, 66.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  19% 254M/1.34G [00:04<00:15, 74.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  19% 264M/1.34G [00:04<00:14, 82.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  20% 274M/1.34G [00:04<00:13, 87.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  20% 281M/1.34G [00:04<00:13, 81.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  21% 287M/1.34G [00:04<00:14, 76.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  21% 294M/1.34G [00:04<00:15, 74.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  22% 304M/1.34G [00:05<00:13, 82.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  23% 313M/1.34G [00:05<00:13, 83.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  23% 320M/1.34G [00:05<00:16, 65.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  23% 321M/1.34G [00:05<00:48, 22.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  23% 322M/1.34G [00:06<01:25, 12.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  24% 323M/1.34G [00:07<02:05, 8.75MB/s]\u001b[A\n",
            "Downloading model.safetensors:  24% 324M/1.34G [00:07<02:21, 7.77MB/s]\u001b[A\n",
            "Downloading model.safetensors:  26% 350M/1.34G [00:07<00:30, 35.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  28% 390M/1.34G [00:07<00:12, 85.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  30% 408M/1.34G [00:10<00:49, 20.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  30% 409M/1.34G [00:10<00:54, 18.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  30% 412M/1.34G [00:10<00:56, 17.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  31% 419M/1.34G [00:10<00:51, 19.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  31% 427M/1.34G [00:11<00:40, 24.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  31% 432M/1.34G [00:11<00:36, 27.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  32% 436M/1.34G [00:11<00:34, 28.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  32% 442M/1.34G [00:11<00:30, 32.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  33% 447M/1.34G [00:11<00:27, 34.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  33% 454M/1.34G [00:11<00:24, 39.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  34% 460M/1.34G [00:11<00:22, 43.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  34% 468M/1.34G [00:11<00:18, 50.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  34% 472M/1.34G [00:11<00:19, 47.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  35% 478M/1.34G [00:12<00:18, 50.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  35% 481M/1.34G [00:12<00:21, 44.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  35% 484M/1.34G [00:12<00:22, 40.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  35% 487M/1.34G [00:12<00:26, 35.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  36% 490M/1.34G [00:12<00:28, 32.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  36% 495M/1.34G [00:12<00:25, 36.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  36% 500M/1.34G [00:12<00:22, 40.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  37% 505M/1.34G [00:12<00:21, 43.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  37% 510M/1.34G [00:12<00:20, 44.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  37% 513M/1.34G [00:13<00:25, 35.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  38% 516M/1.34G [00:13<00:26, 33.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  38% 519M/1.34G [00:13<00:28, 31.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  38% 520M/1.34G [00:13<00:37, 23.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  38% 522M/1.34G [00:13<00:40, 22.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  38% 526M/1.34G [00:13<00:37, 24.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  39% 530M/1.34G [00:13<00:33, 26.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  39% 531M/1.34G [00:13<00:39, 22.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  39% 532M/1.34G [00:14<00:48, 18.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  39% 535M/1.34G [00:14<00:41, 21.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  39% 539M/1.34G [00:14<00:33, 26.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  40% 544M/1.34G [00:14<00:27, 31.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  40% 547M/1.34G [00:14<00:28, 29.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  40% 550M/1.34G [00:14<00:31, 27.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  40% 552M/1.34G [00:14<00:34, 25.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  40% 555M/1.34G [00:14<00:34, 24.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  41% 557M/1.34G [00:15<00:38, 22.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  41% 559M/1.34G [00:15<00:42, 20.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  41% 562M/1.34G [00:15<00:42, 20.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  41% 566M/1.34G [00:15<00:36, 23.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  42% 571M/1.34G [00:15<00:28, 29.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  42% 575M/1.34G [00:15<00:25, 32.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  42% 579M/1.34G [00:15<00:25, 33.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  43% 584M/1.34G [00:15<00:22, 37.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  43% 589M/1.34G [00:16<00:22, 36.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  43% 591M/1.34G [00:16<00:26, 31.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  43% 594M/1.34G [00:16<00:27, 29.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  44% 599M/1.34G [00:16<00:22, 35.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  44% 604M/1.34G [00:16<00:20, 39.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  44% 606M/1.34G [00:16<00:33, 24.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  44% 608M/1.34G [00:16<00:38, 20.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  44% 610M/1.34G [00:17<00:38, 20.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  45% 613M/1.34G [00:17<00:36, 21.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  45% 616M/1.34G [00:17<00:35, 22.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  45% 619M/1.34G [00:17<00:35, 22.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  45% 622M/1.34G [00:17<00:32, 24.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  46% 625M/1.34G [00:17<00:30, 25.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  46% 628M/1.34G [00:17<00:30, 25.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  46% 631M/1.34G [00:17<00:34, 22.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  46% 633M/1.34G [00:18<00:35, 21.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  46% 636M/1.34G [00:18<00:35, 21.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  46% 638M/1.34G [00:18<00:36, 21.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  47% 640M/1.34G [00:18<01:17, 9.88MB/s]\u001b[A\n",
            "Downloading model.safetensors:  47% 644M/1.34G [00:18<00:54, 14.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  47% 646M/1.34G [00:19<00:51, 14.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  47% 649M/1.34G [00:19<00:43, 17.5MB/s]\u001b[A\n",
            "Downloading text_recognition model to /root/.cache/datalab/models/text_recognition/2025_09_23:  92% 11/12 [00:20<00:00, 22.39it/s]\n",
            "Downloading model.safetensors:  48% 655M/1.34G [00:19<00:37, 20.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  48% 658M/1.34G [00:19<00:33, 22.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  48% 662M/1.34G [00:19<00:28, 25.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  48% 665M/1.34G [00:19<00:29, 25.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  49% 668M/1.34G [00:19<00:28, 25.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  49% 670M/1.34G [00:20<00:30, 24.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  49% 673M/1.34G [00:20<00:29, 24.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  49% 676M/1.34G [00:20<00:29, 25.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  50% 680M/1.34G [00:20<00:27, 26.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  50% 685M/1.34G [00:20<00:23, 30.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  50% 687M/1.34G [00:20<00:25, 27.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  50% 690M/1.34G [00:20<00:26, 27.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  51% 694M/1.34G [00:20<00:24, 29.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  51% 697M/1.34G [00:21<00:23, 29.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  51% 699M/1.34G [00:21<00:26, 26.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  51% 701M/1.34G [00:21<00:30, 23.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  51% 704M/1.34G [00:21<00:27, 25.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  52% 707M/1.34G [00:21<00:26, 26.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  52% 709M/1.34G [00:21<00:34, 20.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  52% 712M/1.34G [00:21<00:32, 21.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  52% 714M/1.34G [00:21<00:33, 20.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  52% 717M/1.34G [00:22<00:29, 22.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  52% 720M/1.34G [00:22<00:29, 22.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  53% 722M/1.34G [00:22<00:31, 21.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  53% 725M/1.34G [00:22<00:28, 24.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  53% 729M/1.34G [00:22<00:24, 27.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  53% 732M/1.34G [00:22<00:24, 27.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  54% 735M/1.34G [00:22<00:24, 27.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  54% 738M/1.34G [00:22<00:24, 26.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  54% 742M/1.34G [00:22<00:22, 28.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  54% 746M/1.34G [00:23<00:23, 28.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  55% 749M/1.34G [00:23<00:24, 26.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  55% 753M/1.34G [00:23<00:22, 29.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  55% 756M/1.34G [00:23<00:23, 28.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  55% 759M/1.34G [00:23<00:22, 28.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  56% 762M/1.34G [00:23<00:22, 28.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  56% 766M/1.34G [00:23<00:22, 28.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  56% 769M/1.34G [00:23<00:21, 28.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  56% 771M/1.34G [00:24<00:24, 25.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  56% 774M/1.34G [00:24<00:24, 26.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  57% 777M/1.34G [00:24<00:23, 26.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  57% 781M/1.34G [00:24<00:20, 29.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  57% 784M/1.34G [00:24<00:20, 29.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  57% 787M/1.34G [00:24<00:20, 29.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  57% 789M/1.34G [00:24<00:25, 24.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  58% 790M/1.34G [00:24<00:30, 19.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  58% 793M/1.34G [00:25<00:28, 21.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  58% 795M/1.34G [00:25<00:28, 21.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  58% 797M/1.34G [00:25<00:32, 18.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  58% 799M/1.34G [00:25<00:31, 19.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  58% 801M/1.34G [00:25<00:31, 19.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  59% 803M/1.34G [00:25<00:35, 16.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  59% 804M/1.34G [00:25<00:41, 14.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  59% 808M/1.34G [00:25<00:28, 20.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  59% 812M/1.34G [00:26<00:24, 23.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  59% 816M/1.34G [00:26<00:21, 27.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  60% 821M/1.34G [00:26<00:17, 32.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  60% 825M/1.34G [00:26<00:17, 33.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  60% 828M/1.34G [00:26<00:17, 32.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  61% 831M/1.34G [00:26<00:17, 31.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  61% 833M/1.34G [00:26<00:20, 27.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  61% 835M/1.34G [00:26<00:22, 24.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  61% 837M/1.34G [00:26<00:24, 23.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  61% 840M/1.34G [00:27<00:23, 24.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  61% 843M/1.34G [00:27<00:21, 25.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  62% 845M/1.34G [00:27<00:23, 23.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  62% 849M/1.34G [00:27<00:23, 23.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  62% 852M/1.34G [00:27<00:22, 24.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  62% 856M/1.34G [00:27<00:19, 28.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  63% 859M/1.34G [00:27<00:18, 28.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  63% 862M/1.34G [00:27<00:18, 29.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  63% 866M/1.34G [00:28<00:18, 28.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  63% 870M/1.34G [00:28<00:16, 31.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  64% 876M/1.34G [00:28<00:13, 38.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  64% 880M/1.34G [00:28<00:13, 37.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  64% 884M/1.34G [00:28<00:14, 35.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  65% 887M/1.34G [00:28<00:15, 33.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  65% 890M/1.34G [00:28<00:15, 31.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  65% 893M/1.34G [00:28<00:16, 30.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  65% 896M/1.34G [00:28<00:16, 30.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  66% 899M/1.34G [00:29<00:16, 30.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  66% 902M/1.34G [00:29<00:17, 28.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  66% 905M/1.34G [00:29<00:17, 28.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  66% 911M/1.34G [00:29<00:14, 33.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  67% 914M/1.34G [00:29<00:15, 31.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  67% 917M/1.34G [00:29<00:15, 30.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  67% 920M/1.34G [00:29<00:15, 29.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  67% 924M/1.34G [00:29<00:15, 31.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  68% 928M/1.34G [00:30<00:14, 33.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  68% 930M/1.34G [00:30<00:15, 29.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  68% 932M/1.34G [00:30<00:18, 25.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  68% 935M/1.34G [00:30<00:17, 26.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  68% 939M/1.34G [00:30<00:16, 26.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  69% 942M/1.34G [00:30<00:16, 26.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  69% 945M/1.34G [00:30<00:16, 27.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  69% 949M/1.34G [00:30<00:15, 29.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  69% 953M/1.34G [00:30<00:13, 31.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  70% 954M/1.34G [00:31<00:36, 12.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  70% 957M/1.34G [00:31<00:29, 14.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  70% 960M/1.34G [00:31<00:26, 16.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  70% 964M/1.34G [00:31<00:21, 19.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  70% 967M/1.34G [00:32<00:19, 21.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  71% 970M/1.34G [00:32<00:18, 22.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  71% 974M/1.34G [00:32<00:17, 23.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  71% 978M/1.34G [00:32<00:16, 25.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  71% 980M/1.34G [00:32<00:17, 23.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  72% 982M/1.34G [00:32<00:17, 22.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  72% 986M/1.34G [00:32<00:15, 26.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  72% 989M/1.34G [00:32<00:14, 26.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  72% 992M/1.34G [00:33<00:14, 26.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  72% 994M/1.34G [00:33<00:15, 25.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  73% 997M/1.34G [00:33<00:14, 26.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  73% 0.98G/1.34G [00:33<00:14, 27.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  73% 0.98G/1.34G [00:33<00:13, 29.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  73% 0.98G/1.34G [00:33<00:14, 26.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  74% 0.99G/1.34G [00:33<00:14, 25.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  74% 0.99G/1.34G [00:33<00:15, 24.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  74% 0.99G/1.34G [00:33<00:14, 25.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  74% 0.99G/1.34G [00:34<00:13, 26.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  74% 1.00G/1.34G [00:34<00:14, 26.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  75% 1.00G/1.34G [00:34<00:13, 26.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  75% 1.00G/1.34G [00:34<00:13, 26.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  75% 1.01G/1.34G [00:34<00:13, 25.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  75% 1.01G/1.34G [00:34<00:13, 26.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  75% 1.01G/1.34G [00:34<00:12, 27.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  76% 1.01G/1.34G [00:34<00:12, 28.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  76% 1.02G/1.34G [00:34<00:11, 29.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  76% 1.02G/1.34G [00:35<00:12, 27.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  76% 1.02G/1.34G [00:35<00:15, 21.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  77% 1.03G/1.34G [00:35<00:14, 23.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  77% 1.03G/1.34G [00:35<00:13, 25.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  77% 1.03G/1.34G [00:35<00:11, 27.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  77% 1.04G/1.34G [00:35<00:10, 30.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  78% 1.04G/1.34G [00:35<00:12, 26.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  78% 1.04G/1.34G [00:35<00:11, 27.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  78% 1.04G/1.34G [00:36<00:11, 27.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  78% 1.05G/1.34G [00:36<00:16, 18.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  79% 1.06G/1.34G [00:36<00:10, 29.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  79% 1.06G/1.34G [00:36<00:10, 28.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  79% 1.06G/1.34G [00:36<00:10, 28.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  79% 1.06G/1.34G [00:36<00:11, 26.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  80% 1.07G/1.34G [00:37<00:13, 22.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  80% 1.07G/1.34G [00:37<00:12, 23.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  80% 1.07G/1.34G [00:37<00:12, 22.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  80% 1.07G/1.34G [00:37<00:12, 22.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  80% 1.08G/1.34G [00:37<00:19, 14.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  80% 1.08G/1.34G [00:38<00:23, 11.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  81% 1.08G/1.34G [00:38<00:21, 13.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  81% 1.08G/1.34G [00:38<00:20, 13.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  81% 1.08G/1.34G [00:38<00:16, 17.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  81% 1.09G/1.34G [00:38<00:13, 20.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  81% 1.09G/1.34G [00:38<00:11, 22.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  82% 1.09G/1.34G [00:38<00:15, 17.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  82% 1.10G/1.34G [00:38<00:13, 19.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  82% 1.10G/1.34G [00:39<00:10, 23.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  82% 1.10G/1.34G [00:39<00:10, 25.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  83% 1.11G/1.34G [00:39<00:09, 25.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  83% 1.11G/1.34G [00:39<00:09, 26.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  83% 1.11G/1.34G [00:39<00:10, 24.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  83% 1.12G/1.34G [00:39<00:09, 25.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  83% 1.12G/1.34G [00:39<00:09, 26.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  84% 1.12G/1.34G [00:39<00:08, 28.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  84% 1.12G/1.34G [00:40<00:12, 18.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  84% 1.13G/1.34G [00:40<00:11, 20.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  84% 1.13G/1.34G [00:40<00:11, 20.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  84% 1.13G/1.34G [00:40<00:10, 21.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  85% 1.13G/1.34G [00:40<00:09, 23.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  85% 1.14G/1.34G [00:40<00:07, 27.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  85% 1.14G/1.34G [00:40<00:07, 27.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  85% 1.15G/1.34G [00:40<00:06, 30.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  86% 1.15G/1.34G [00:41<00:07, 29.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  86% 1.15G/1.34G [00:41<00:07, 28.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  86% 1.15G/1.34G [00:41<00:07, 28.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  86% 1.16G/1.34G [00:41<00:06, 28.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  87% 1.16G/1.34G [00:41<00:06, 28.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  87% 1.16G/1.34G [00:41<00:07, 26.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  87% 1.16G/1.34G [00:41<00:07, 24.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  87% 1.17G/1.34G [00:41<00:08, 22.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  87% 1.17G/1.34G [00:42<00:08, 22.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  87% 1.17G/1.34G [00:42<00:07, 23.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  88% 1.17G/1.34G [00:42<00:08, 21.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  88% 1.18G/1.34G [00:42<00:07, 23.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  88% 1.18G/1.34G [00:42<00:08, 19.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  88% 1.18G/1.34G [00:42<00:07, 21.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  88% 1.19G/1.34G [00:42<00:07, 22.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  89% 1.19G/1.34G [00:42<00:06, 23.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  89% 1.19G/1.34G [00:43<00:05, 27.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  89% 1.20G/1.34G [00:43<00:05, 27.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  89% 1.20G/1.34G [00:43<00:06, 24.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  90% 1.20G/1.34G [00:43<00:05, 25.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  90% 1.21G/1.34G [00:43<00:05, 28.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  90% 1.21G/1.34G [00:43<00:05, 27.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  90% 1.21G/1.34G [00:43<00:05, 25.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  91% 1.21G/1.34G [00:43<00:05, 26.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  91% 1.22G/1.34G [00:43<00:04, 27.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  91% 1.22G/1.34G [00:44<00:04, 28.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  91% 1.22G/1.34G [00:44<00:04, 27.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  91% 1.22G/1.34G [00:44<00:05, 24.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  92% 1.23G/1.34G [00:44<00:04, 25.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  92% 1.23G/1.34G [00:44<00:04, 27.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  92% 1.23G/1.34G [00:44<00:04, 27.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  92% 1.24G/1.34G [00:44<00:04, 28.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  92% 1.24G/1.34G [00:44<00:04, 25.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  93% 1.24G/1.34G [00:45<00:03, 28.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  93% 1.25G/1.34G [00:45<00:03, 30.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  93% 1.25G/1.34G [00:45<00:02, 32.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  93% 1.25G/1.34G [00:45<00:03, 29.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  94% 1.25G/1.34G [00:45<00:03, 28.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  94% 1.26G/1.34G [00:45<00:03, 28.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  94% 1.26G/1.34G [00:45<00:02, 28.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  94% 1.26G/1.34G [00:45<00:02, 28.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  95% 1.27G/1.34G [00:45<00:02, 27.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  95% 1.27G/1.34G [00:46<00:02, 27.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  95% 1.27G/1.34G [00:46<00:02, 28.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  95% 1.28G/1.34G [00:46<00:02, 31.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  96% 1.28G/1.34G [00:46<00:01, 36.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  96% 1.29G/1.34G [00:46<00:01, 33.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  96% 1.29G/1.34G [00:46<00:01, 31.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  96% 1.29G/1.34G [00:46<00:01, 27.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  96% 1.29G/1.34G [00:46<00:02, 25.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  97% 1.29G/1.34G [00:46<00:01, 26.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  97% 1.30G/1.34G [00:47<00:01, 25.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  97% 1.30G/1.34G [00:47<00:01, 26.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  97% 1.30G/1.34G [00:47<00:01, 30.0MB/s]\u001b[A\n",
            "Downloading model.safetensors:  98% 1.31G/1.34G [00:47<00:01, 30.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  98% 1.31G/1.34G [00:47<00:01, 28.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  98% 1.31G/1.34G [00:47<00:01, 26.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  98% 1.31G/1.34G [00:47<00:01, 24.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  98% 1.32G/1.34G [00:47<00:00, 28.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  99% 1.32G/1.34G [00:47<00:00, 31.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  99% 1.33G/1.34G [00:48<00:00, 31.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  99% 1.33G/1.34G [00:48<00:00, 30.2MB/s]\u001b[A\n",
            "Downloading model.safetensors:  99% 1.33G/1.34G [00:48<00:00, 26.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  99% 1.33G/1.34G [00:48<00:00, 24.1MB/s]\u001b[A\n",
            "Downloading model.safetensors: 100% 1.33G/1.34G [00:48<00:00, 23.8MB/s]\u001b[A\n",
            "Downloading model.safetensors: 100% 1.34G/1.34G [00:48<00:00, 21.9MB/s]\u001b[A\n",
            "Downloading model.safetensors: 100% 1.34G/1.34G [00:48<00:00, 29.5MB/s]\n",
            "Downloading text_recognition model to /root/.cache/datalab/models/text_recognition/2025_09_23: 100% 12/12 [00:49<00:00,  4.13s/it]\n",
            "Downloading manifest.json: 100% 106/106 [00:00<00:00, 317kB/s]\n",
            "Downloading table_recognition model to /root/.cache/datalab/models/table_recognition/2025_02_18:   0% 0/5 [00:00<?, ?it/s]\n",
            "Downloading .gitattributes: 100% 1.48k/1.48k [00:00<00:00, 4.57MB/s]\n",
            "\n",
            "Downloading README.md:   0% 0.00/33.0 [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading README.md: 100% 33.0/33.0 [00:00<00:00, 63.7kB/s]\n",
            "Downloading config.json: 100% 6.22k/6.22k [00:00<00:00, 9.83MB/s]\n",
            "\n",
            "Downloading model.safetensors:   0% 0.00/201M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading preprocessor_config.json: 100% 564/564 [00:00<00:00, 1.70MB/s]\n",
            "\n",
            "Downloading model.safetensors:  16% 32.0M/201M [00:00<00:00, 333MB/s]\u001b[A\n",
            "Downloading model.safetensors:  32% 65.0M/201M [00:00<00:00, 336MB/s]\u001b[A\n",
            "Downloading model.safetensors:  46% 92.0M/201M [00:00<00:00, 305MB/s]\u001b[A\n",
            "Downloading model.safetensors:  58% 116M/201M [00:00<00:00, 282MB/s] \u001b[A\n",
            "Downloading model.safetensors:  70% 142M/201M [00:00<00:00, 278MB/s]\u001b[A\n",
            "Downloading model.safetensors:  84% 169M/201M [00:00<00:00, 279MB/s]\u001b[A\n",
            "Downloading model.safetensors: 100% 201M/201M [00:00<00:00, 293MB/s]\n",
            "Downloading table_recognition model to /root/.cache/datalab/models/table_recognition/2025_02_18: 100% 5/5 [00:01<00:00,  4.90it/s]\n",
            "Downloading manifest.json: 100% 127/127 [00:00<00:00, 420kB/s]\n",
            "Downloading text_detection model to /root/.cache/datalab/models/text_detection/2025_05_07:   0% 0/6 [00:00<?, ?it/s]\n",
            "Downloading model.safetensors:   0% 0.00/73.4M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading preprocessor_config.json: 100% 373/373 [00:00<00:00, 1.33MB/s]\n",
            "\n",
            "\n",
            "Downloading .gitattributes: 100% 1.48k/1.48k [00:00<00:00, 5.13MB/s]\n",
            "\n",
            "\n",
            "Downloading README.md: 100% 393/393 [00:00<00:00, 1.87MB/s]\n",
            "\n",
            "\n",
            "Downloading config.json: 100% 858/858 [00:00<00:00, 3.74MB/s]\n",
            "\n",
            "\n",
            "Downloading training_args.bin: 100% 5.49k/5.49k [00:00<00:00, 18.8MB/s]\n",
            "\n",
            "Downloading model.safetensors:   1% 1.00M/73.4M [00:00<00:14, 5.31MB/s]\u001b[A\n",
            "Downloading model.safetensors:   3% 2.00M/73.4M [00:00<00:14, 5.32MB/s]\u001b[A\n",
            "Downloading model.safetensors:   4% 3.00M/73.4M [00:00<00:11, 6.45MB/s]\u001b[A\n",
            "Downloading model.safetensors:   7% 5.00M/73.4M [00:00<00:07, 9.09MB/s]\u001b[A\n",
            "Downloading model.safetensors:  10% 7.00M/73.4M [00:00<00:06, 11.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  14% 10.0M/73.4M [00:00<00:04, 16.4MB/s]\u001b[A\n",
            "Downloading model.safetensors:  19% 14.0M/73.4M [00:01<00:02, 21.9MB/s]\u001b[A\n",
            "Downloading model.safetensors:  26% 19.0M/73.4M [00:01<00:01, 29.5MB/s]\u001b[A\n",
            "Downloading model.safetensors:  35% 26.0M/73.4M [00:01<00:01, 41.1MB/s]\u001b[A\n",
            "Downloading model.safetensors:  48% 35.0M/73.4M [00:01<00:00, 54.6MB/s]\u001b[A\n",
            "Downloading model.safetensors:  64% 47.0M/73.4M [00:01<00:00, 74.1MB/s]\u001b[A\n",
            "Downloading model.safetensors: 100% 73.4M/73.4M [00:01<00:00, 47.5MB/s]\n",
            "Downloading text_detection model to /root/.cache/datalab/models/text_detection/2025_05_07: 100% 6/6 [00:01<00:00,  3.14it/s]\n",
            "Downloading manifest.json: 100% 161/161 [00:00<00:00, 421kB/s]\n",
            "Downloading ocr_error_detection model to /root/.cache/datalab/models/ocr_error_detection/2025_02_18:   0% 0/8 [00:00<?, ?it/s]\n",
            "Downloading tokenizer_config.json: 100% 1.17k/1.17k [00:00<00:00, 3.94MB/s]\n",
            "\n",
            "Downloading special_tokens_map.json: 100% 695/695 [00:00<00:00, 4.05MB/s]\n",
            "\n",
            "Downloading model.safetensors:   0% 0.00/258M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading .gitattributes: 100% 1.48k/1.48k [00:00<00:00, 5.52MB/s]\n",
            "\n",
            "\n",
            "Downloading config.json: 100% 647/647 [00:00<00:00, 2.38MB/s]\n",
            "\n",
            "Downloading model.safetensors:  16% 41.0M/258M [00:00<00:00, 429MB/s]\u001b[A\n",
            "Downloading model.safetensors:  26% 66.0M/258M [00:00<00:00, 330MB/s]\u001b[A\n",
            "Downloading model.safetensors:  39% 101M/258M [00:00<00:00, 347MB/s] \u001b[A\n",
            "\n",
            "Downloading tokenizer.json:   0% 0.00/2.78M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading vocab.txt:   0% 0.00/972k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading README.md: 100% 32.0/32.0 [00:00<00:00, 158kB/s]\n",
            "\n",
            "\n",
            "Downloading tokenizer.json:  36% 1.00M/2.78M [00:00<00:01, 1.70MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading vocab.txt: 100% 972k/972k [00:00<00:00, 1.62MB/s]\n",
            "\n",
            "Downloading tokenizer.json: 100% 2.78M/2.78M [00:00<00:00, 4.62MB/s]\n",
            "\n",
            "Downloading model.safetensors:  66% 170M/258M [00:01<00:00, 130MB/s] \u001b[A\n",
            "Downloading model.safetensors:  73% 188M/258M [00:01<00:00, 139MB/s]\u001b[A\n",
            "Downloading model.safetensors:  84% 216M/258M [00:01<00:00, 166MB/s]\u001b[A\n",
            "Downloading model.safetensors:  85% 219M/258M [00:01<00:00, 80.8MB/s]\u001b[A\n",
            "Downloading model.safetensors:  85% 220M/258M [00:02<00:00, 43.3MB/s]\u001b[A\n",
            "Downloading model.safetensors:  86% 221M/258M [00:02<00:01, 26.7MB/s]\u001b[A\n",
            "Downloading model.safetensors:  86% 222M/258M [00:03<00:02, 17.6MB/s]\u001b[A\n",
            "Downloading model.safetensors: 100% 258M/258M [00:03<00:00, 76.4MB/s]\n",
            "Downloading ocr_error_detection model to /root/.cache/datalab/models/ocr_error_detection/2025_02_18: 100% 8/8 [00:03<00:00,  2.08it/s]\n",
            "Recognizing Layout: 100% 9/9 [00:07<00:00,  1.23it/s]\n",
            "Running OCR Error Detection: 100% 1/1 [00:00<00:00, 16.81it/s]\n",
            "Detecting bboxes: 100% 1/1 [00:03<00:00,  3.85s/it]\n",
            "Recognizing Text: 100% 167/167 [00:12<00:00, 13.00it/s]\n",
            "Recognizing tables: 100% 1/1 [00:01<00:00,  1.35s/it]\n",
            "Detecting bboxes: 100% 2/2 [00:03<00:00,  1.98s/it]\n",
            "Recognizing Text:  98% 776/791 [00:56<00:03,  4.55it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1406, in main\n",
            "    rv = self.invoke(ctx)\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1269, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 824, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/marker/scripts/convert_single.py\", line 38, in convert_single_cli\n",
            "    rendered = converter(fpath)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/marker/converters/pdf.py\", line 195, in __call__\n",
            "    document = self.build_document(temp_path)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/marker/converters/pdf.py\", line 189, in build_document\n",
            "    processor(document)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/marker/processors/table.py\", line 134, in __call__\n",
            "    self.assign_ocr_lines(tables, table_data)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/marker/processors/table.py\", line 680, in assign_ocr_lines\n",
            "    ocr_results = self.get_ocr_results(table_images=det_images, ocr_polys=ocr_polys)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/marker/processors/table.py\", line 636, in get_ocr_results\n",
            "    ocr_results = self.recognition_model(\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/surya/recognition/__init__.py\", line 431, in __call__\n",
            "    predicted_tokens, batch_bboxes, scores, _ = self.foundation_predictor.prediction_loop(\n",
            "                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/surya/foundation/__init__.py\", line 827, in prediction_loop\n",
            "    updated_inputs, outputs = self.decode(\n",
            "                              ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/surya/foundation/__init__.py\", line 341, in decode\n",
            "    outputs = self.model(\n",
            "              ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/surya/common/surya/__init__.py\", line 468, in forward\n",
            "    outputs = self.decoder(\n",
            "              ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/surya/common/surya/decoder/__init__.py\", line 504, in forward\n",
            "    layer_outputs = decoder_layer(\n",
            "                    ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/surya/common/surya/decoder/__init__.py\", line 302, in forward\n",
            "    hidden_states, self_attn_weights = self.self_attn(\n",
            "                                       ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/surya/common/surya/decoder/__init__.py\", line 188, in forward\n",
            "    key_states, value_states = past_key_value.update(\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/surya/foundation/cache/dynamic_ops.py\", line 83, in update\n",
            "    return update_fn(\n",
            "           ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/surya/foundation/cache/dynamic_ops.py\", line 363, in _decode_update\n",
            "    tgt_indices = tgt_indices.clamp(max=max_cache_len - 1)  # safety\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/marker_single\", line 8, in <module>\n",
            "    sys.exit(convert_single_cli())\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1485, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1418, in main\n",
            "    echo(file=sys.stderr)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/utils.py\", line 321, in echo\n",
            "    file.write(out)  # type: ignore\n",
            "    ^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "Recognizing Text:  98% 776/791 [03:36<00:04,  3.59it/s]\n",
            "\n",
            "✓ Conversion complete! Check the ./output directory.\n"
          ]
        }
      ],
      "source": [
        "# Basic conversion (fast, good quality)\n",
        "!marker_single \"{input_file}\" --output_format html --output_dir ./output --force_ocr\n",
        "\n",
        "print(\"\\n✓ Conversion complete! Check the ./output directory.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "convert-advanced"
      },
      "source": [
        "### Alternative: High-Accuracy Conversion with LLM\n",
        "\n",
        "If you configured your Gemini API key above, run this cell for highest accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "convert-llm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39fb1355-d843-4976-c209-00f6009d72ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-06 16:41:34.605602: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770396094.637316    5514 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770396094.647176    5514 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770396094.671225    5514 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770396094.671253    5514 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770396094.671260    5514 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770396094.671267    5514 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-06 16:41:34.678120: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Recognizing Layout: 100% 2/2 [00:02<00:00,  1.31s/it]\n",
            "Running OCR Error Detection: 100% 1/1 [00:00<00:00, 40.30it/s]\n",
            "Detecting bboxes: 100% 1/1 [00:02<00:00,  2.82s/it]\n",
            "Recognizing Text: 100% 23/23 [00:11<00:00,  1.95it/s]\n",
            "Recognizing tables: 100% 1/1 [00:01<00:00,  1.08s/it]\n",
            "Detecting bboxes: 100% 1/1 [00:02<00:00,  2.44s/it]\n",
            "Recognizing Text:  98% 405/413 [00:10<00:00, 44.42it/s]"
          ]
        }
      ],
      "source": [
        "# High-accuracy conversion with LLM (requires API key from step 4)\n",
        "# Uncomment to use:\n",
        "!marker_single \"{input_file}\" --output_format html --output_dir ./output --use_llm --force_ocr\n",
        "print(\"\\n✓ High-accuracy conversion complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-results"
      },
      "source": [
        "## 6. View Results\n",
        "\n",
        "Display the converted markdown content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "view-markdown",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "687baec5-9a5c-4482-e1ad-83407ab26f4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Searching for output files...\n",
            "\n",
            "  output does not exist\n",
            "  /content/output does not exist\n",
            "  output does not exist\n",
            "\n",
            "🔍 Searching entire /content directory...\n",
            "  Found: /content/sample_data/README.md\n",
            "  Found: /content/output_tables/1-G50 CONSOLIDER MOIS DE JANVIER 2025/1-G50 CONSOLIDER MOIS DE JANVIER 2025_meta.json\n",
            "  Found: /content/output_tables/1-G50 CONSOLIDER MOIS DE JANVIER 2025/1-G50 CONSOLIDER MOIS DE JANVIER 2025.md\n",
            "\n",
            "================================================================================\n",
            "📚 Found 3 file(s):\n",
            "================================================================================\n",
            "\n",
            "  📄 README.md\n",
            "      Path: /content/sample_data/README.md\n",
            "      Size: 962 bytes\n",
            "\n",
            "  📄 1-G50 CONSOLIDER MOIS DE JANVIER 2025_meta.json\n",
            "      Path: /content/output_tables/1-G50 CONSOLIDER MOIS DE JANVIER 2025/1-G50 CONSOLIDER MOIS DE JANVIER 2025_meta.json\n",
            "      Size: 5,248 bytes\n",
            "\n",
            "  📄 1-G50 CONSOLIDER MOIS DE JANVIER 2025.md\n",
            "      Path: /content/output_tables/1-G50 CONSOLIDER MOIS DE JANVIER 2025/1-G50 CONSOLIDER MOIS DE JANVIER 2025.md\n",
            "      Size: 326,755 bytes\n",
            "\n",
            "================================================================================\n",
            "📖 Reading: README.md\n",
            "================================================================================\n",
            "\n",
            "This directory includes a few sample datasets to get you started.\n",
            "\n",
            "*   `california_housing_data*.csv` is California housing data from the 1990 US\n",
            "    Census; more information is available at:\n",
            "    https://docs.google.com/document/d/e/2PACX-1vRhYtsvc5eOR2FWNCwaBiKL6suIOrxJig8LcSBbmCbyYsayia_DvPOOBlXZ4CAlQ5nlDD8kTaIDRwrN/pub\n",
            "\n",
            "*   `mnist_*.csv` is a small sample of the\n",
            "    [MNIST database](https://en.wikipedia.org/wiki/MNIST_database), which is\n",
            "    described at: http://yann.lecun.com/exdb/mnist/\n",
            "\n",
            "*   `anscombe.json` contains a copy of\n",
            "    [Anscombe's quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet); it\n",
            "    was originally described in\n",
            "\n",
            "    Anscombe, F. J. (1973). 'Graphs in Statistical Analysis'. American\n",
            "    Statistician. 27 (1): 17-21. JSTOR 2682899.\n",
            "\n",
            "    and our copy was prepared by the\n",
            "    [vega_datasets library](https://github.com/altair-viz/vega_datasets/blob/4f67bdaad10f45e3549984e17e1b3088c731503d/vega_datasets/_data/anscombe.json).\n",
            "\n",
            "\n",
            "================================================================================\n",
            "✓ Total length: 962 characters\n",
            "✓ Lines: 20\n",
            "✓ Full path: /content/sample_data/README.md\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"🔍 Searching for output files...\\n\")\n",
        "\n",
        "# Try multiple possible locations\n",
        "possible_paths = [\n",
        "    Path(\"./output\"),\n",
        "    Path(\"/content/output\"),\n",
        "    Path(\"output\"),\n",
        "]\n",
        "\n",
        "found_files = []\n",
        "output_dir = None\n",
        "\n",
        "# Check each possible location\n",
        "for path in possible_paths:\n",
        "    if path.exists():\n",
        "        files = [f for f in path.rglob('*') if f.is_file()]\n",
        "        if files:\n",
        "            print(f\"✓ Found files in: {path}\")\n",
        "            found_files.extend(files)\n",
        "            output_dir = path\n",
        "            break\n",
        "        else:\n",
        "            print(f\"  {path} exists but is empty\")\n",
        "    else:\n",
        "        print(f\"  {path} does not exist\")\n",
        "\n",
        "# If still not found, search the entire /content directory\n",
        "if not found_files:\n",
        "    print(\"\\n🔍 Searching entire /content directory...\")\n",
        "    content_dir = Path(\"/content\")\n",
        "    for item in content_dir.rglob('*'):\n",
        "        if item.is_file() and (item.suffix == '.md' or 'output' in str(item).lower()):\n",
        "            found_files.append(item)\n",
        "            print(f\"  Found: {item}\")\n",
        "\n",
        "# Display results\n",
        "if found_files:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"📚 Found {len(found_files)} file(s):\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    for f in found_files:\n",
        "        print(f\"  📄 {f.name}\")\n",
        "        print(f\"      Path: {f}\")\n",
        "        print(f\"      Size: {f.stat().st_size:,} bytes\\n\")\n",
        "\n",
        "    # Prioritize .md files over .json files\n",
        "    md_files = [f for f in found_files if f.suffix == '.md']\n",
        "    output_file = md_files[0] if md_files else found_files[0]\n",
        "\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"📖 Reading: {output_file.name}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    try:\n",
        "        with open(output_file, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Display first 3000 characters\n",
        "        preview_length = 3000\n",
        "        print(content[:preview_length])\n",
        "\n",
        "        if len(content) > preview_length:\n",
        "            print(f\"\\n\\n... [truncated - showing first {preview_length:,} of {len(content):,} characters] ...\")\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"✓ Total length: {len(content):,} characters\")\n",
        "        print(f\"✓ Lines: {content.count(chr(10)) + 1:,}\")\n",
        "        print(f\"✓ Full path: {output_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error reading file: {e}\")\n",
        "else:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"❌ No output files found anywhere!\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nDebug: Let's check what's in /content:\")\n",
        "    !ls -la /content/\n",
        "    print(\"\\nTry running the conversion cell again.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download-section"
      },
      "source": [
        "## 7. Download Results\n",
        "\n",
        "Download the converted files to your computer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download-files",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "collapsed": true,
        "outputId": "d2ceb632-665d-497c-8d66-82e4dc741c70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2 file(s) to download:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3b50830c-9556-40a3-8d3c-089d43ae01cd\", \"1-G50 CONSOLIDER MOIS DE JANVIER 2025_meta.json\", 5248)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Downloaded: 1-G50 CONSOLIDER MOIS DE JANVIER 2025/1-G50 CONSOLIDER MOIS DE JANVIER 2025_meta.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_17416c05-0e0e-4907-9446-020d82f522e9\", \"1-G50 CONSOLIDER MOIS DE JANVIER 2025.md\", 326755)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Downloaded: 1-G50 CONSOLIDER MOIS DE JANVIER 2025/1-G50 CONSOLIDER MOIS DE JANVIER 2025.md\n",
            "\n",
            "✓ Successfully downloaded 2 file(s)!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Try multiple possible locations\n",
        "possible_paths = [\n",
        "    Path(\"./output\"),\n",
        "    Path(\"/content/output\"),\n",
        "    Path(\"output\"),\n",
        "    Path(\"./output_html\"),\n",
        "    Path(\"/content/output_html\"),\n",
        "    Path(\"output_html\"),\n",
        "    Path(\"/content/output_tables\"),\n",
        "    Path(\"output_tables\"),\n",
        "\n",
        "]\n",
        "\n",
        "output_dir = None\n",
        "for path in possible_paths:\n",
        "    if path.exists():\n",
        "        output_dir = path\n",
        "        break\n",
        "\n",
        "if output_dir and output_dir.exists():\n",
        "    file_count = 0\n",
        "\n",
        "    # Search recursively for all files (including in subdirectories)\n",
        "    all_files = []\n",
        "    for filepath in output_dir.rglob('*'):\n",
        "        if filepath.is_file():\n",
        "            all_files.append(filepath)\n",
        "\n",
        "    print(f\"Found {len(all_files)} file(s) to download:\\n\")\n",
        "\n",
        "    for filepath in all_files:\n",
        "        try:\n",
        "            # Show relative path for clarity\n",
        "            rel_path = filepath.relative_to(output_dir)\n",
        "            files.download(str(filepath))\n",
        "            print(f\"✓ Downloaded: {rel_path}\")\n",
        "            file_count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error downloading {filepath.name}: {e}\")\n",
        "\n",
        "    if file_count == 0:\n",
        "        print(\"No files found to download.\")\n",
        "    else:\n",
        "        print(f\"\\n✓ Successfully downloaded {file_count} file(s)!\")\n",
        "else:\n",
        "    print(\"❌ Output directory not found. Run the conversion first!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-images"
      },
      "source": [
        "## 8. View Extracted Images (if any)\n",
        "\n",
        "If your document had images, they'll be extracted to a subfolder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "view-images-code"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "output_dir = Path(\"./output\")\n",
        "\n",
        "# Look for image directories\n",
        "image_dirs = [d for d in output_dir.iterdir() if d.is_dir()]\n",
        "\n",
        "if image_dirs:\n",
        "    for img_dir in image_dirs:\n",
        "        image_files = list(img_dir.glob(\"*.png\")) + list(img_dir.glob(\"*.jpg\")) + list(img_dir.glob(\"*.jpeg\"))\n",
        "\n",
        "        if image_files:\n",
        "            print(f\"\\n📁 Found {len(image_files)} image(s) in {img_dir.name}/\\n\")\n",
        "\n",
        "            for img_path in image_files[:5]:  # Show first 5 images\n",
        "                print(f\"  🖼️  {img_path.name}\")\n",
        "                display(Image(filename=str(img_path), width=400))\n",
        "\n",
        "            if len(image_files) > 5:\n",
        "                print(f\"\\n... and {len(image_files) - 5} more image(s)\")\n",
        "else:\n",
        "    print(\"No extracted images found (or image extraction was disabled).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "advanced-options"
      },
      "source": [
        "## Advanced Options\n",
        "\n",
        "### Convert to JSON Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "convert-json"
      },
      "outputs": [],
      "source": [
        "# Convert to JSON instead of markdown\n",
        "!marker_single \"{input_file}\" --output_format json --output_dir ./output_json\n",
        "print(\"✓ JSON conversion complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "convert-html"
      },
      "source": [
        "### Convert to HTML Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "convert-html-code"
      },
      "outputs": [],
      "source": [
        "# Convert to HTML\n",
        "!marker_single \"{input_file}\" --output_format html --output_dir ./output_html\n",
        "print(\"✓ HTML conversion complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "extract-tables"
      },
      "source": [
        "### Extract Tables Only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "extract-tables-code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9380467-8746-445e-e38d-abf4cb52eb3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-09 00:36:57.792443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770597417.812146    3770 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770597417.818094    3770 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770597417.833234    3770 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770597417.833265    3770 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770597417.833269    3770 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770597417.833272    3770 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-09 00:36:57.837835: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Recognizing Layout: 100% 9/9 [00:07<00:00,  1.24it/s]\n",
            "Running OCR Error Detection: 100% 1/1 [00:00<00:00, 17.44it/s]\n",
            "Detecting bboxes: 100% 1/1 [00:04<00:00,  4.03s/it]\n",
            "Recognizing tables: 100% 1/1 [00:01<00:00,  1.15s/it]\n",
            "Detecting bboxes: 100% 2/2 [00:04<00:00,  2.18s/it]\n",
            "Recognizing Text: 100% 791/791 [03:57<00:00,  3.33it/s]\n",
            "2026-02-09 00:41:45,010 [INFO] marker: Saved markdown to ./output_tables/1-G50 CONSOLIDER MOIS DE JANVIER 2025\n",
            "INFO:marker:Saved markdown to ./output_tables/1-G50 CONSOLIDER MOIS DE JANVIER 2025\n",
            "2026-02-09 00:41:45,010 [INFO] marker: Total time: 260.9892294406891\n",
            "INFO:marker:Total time: 260.9892294406891\n",
            "✓ Table extraction complete!\n"
          ]
        }
      ],
      "source": [
        "# Extract only tables from the document\n",
        "!marker_single \"{input_file}\" --output_dir ./output_tables --converter_cls marker.converters.table.TableConverter\n",
        "print(\"✓ Table extraction complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "batch-conversion"
      },
      "source": [
        "### Batch Convert Multiple Files\n",
        "\n",
        "Upload multiple files and convert them all at once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "batch-upload"
      },
      "outputs": [],
      "source": [
        "# Upload multiple files\n",
        "uploaded_files = files.upload()\n",
        "\n",
        "# Create input directory and move files\n",
        "!mkdir -p ./batch_input\n",
        "for filename in uploaded_files.keys():\n",
        "    !mv \"{filename}\" ./batch_input/\n",
        "\n",
        "print(f\"✓ Uploaded {len(uploaded_files)} files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "batch-convert"
      },
      "outputs": [],
      "source": [
        "# Convert all files in batch\n",
        "!marker ./batch_input --output_dir ./batch_output --workers 4\n",
        "print(\"✓ Batch conversion complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tips"
      },
      "source": [
        "## Tips & Troubleshooting\n",
        "\n",
        "**For better accuracy:**\n",
        "- Use `--use_llm` flag with a Gemini API key\n",
        "- Use `--force_ocr` for documents with garbled text\n",
        "- Use `--redo_inline_math` for highest quality math conversion\n",
        "\n",
        "**Common flags:**\n",
        "- `--page_range \"0,5-10,20\"` - Process specific pages\n",
        "- `--paginate_output` - Add page numbers to output\n",
        "- `--disable_image_extraction` - Don't extract images\n",
        "- `--debug` - Enable debug mode for troubleshooting\n",
        "\n",
        "**Supported languages:** [Full list](https://github.com/VikParuchuri/surya/blob/master/surya/recognition/languages.py)\n",
        "\n",
        "**Memory issues?**\n",
        "- Reduce worker count\n",
        "- Split large PDFs into smaller files\n",
        "- Use a GPU runtime with more RAM"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "installation",
        "upload-section",
        "optional-llm",
        "convert-section",
        "convert-advanced",
        "view-results",
        "view-images"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}